{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebookPyTorch_DinAE_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+fSTlkV9Yba3Gwut4EE7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfablet/DinAE/blob/master/notebookPyTorch_DinAE_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhV5CxIkMpmw",
        "colab_type": "text"
      },
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l64w7gvOMXJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "5e4cf400-bdd6-412d-f000-67c1d931ac24"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import os\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn import decomposition\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUmFTdFnVFDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "875bbe7e-e7a1-429e-8553-87f4cf8704ce"
      },
      "source": [
        "!pip install torchviz\n",
        "import torchviz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q35bMkwXVR-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ca371558-309d-49fa-aee3-b3a308f1a087"
      },
      "source": [
        "#!mkdir /content/PythonCode\n",
        "#os.mkdir('/content/PythonCode')\n",
        "#os.chdir('/content/PythonCode/')\n",
        "#!git clone https://github.com/CIA-Oceanix/DinAE.git\n",
        "os.chdir('/content/PythonCode/DinAE')\n",
        "!git pull\n",
        "#import DinAE"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/CIA-Oceanix/DinAE\n",
            "   1008e4b..0431431  master     -> origin/master\n",
            "Updating 1008e4b..0431431\n",
            "Fast-forward\n",
            " dinAE_solver_torch.py | 23 \u001b[32m++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 22 insertions(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF-Con2F9HO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('/content/PythonCode2')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z0kWSenXeya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.mkdir('/content/PythonCode')\n",
        "#os.chdir('/content/PythonCode')\n",
        "#!git clone https://github.com/CIA-Oceanix/DinAE.git\n",
        "os.chdir('/content/PythonCode/DinAE')\n",
        "import dinAE_solver_torch as dinAE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhXvnm4tOifI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c26a9a3c-1441-4012-e599-a2bd06c46e50"
      },
      "source": [
        "# mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls /content/drive/My\\ Drive/ResearchData/patchDataset_OcciputData.nc\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/')\n",
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "'/content/drive/My Drive/ResearchData/patchDataset_OcciputData.nc'\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBoD1pUwM3bj",
        "colab_type": "text"
      },
      "source": [
        "# Load and prepare data (MNIST/image data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0OJYM8JOjVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### load datasets\n",
        "flagDataset = 0\n",
        "\n",
        "if flagDataset == 0: ## MNIST\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "elif flagDataset == 1: ## FASHION MNIST\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "#elif flagDataset == 2: ## OCCIPUT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzV6xuhYOnDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data normalization\n",
        "if 1*1:\n",
        "  meanTr     = np.mean(x_train[:]) \n",
        "  x_train    = x_train - meanTr\n",
        "  x_test     = x_test - meanTr\n",
        "\n",
        "  # scale wrt std\n",
        "  stdTr      = np.sqrt( np.mean( x_train**2 ) )\n",
        "  x_train    = x_train / stdTr\n",
        "  x_test     = x_test / stdTr\n",
        "  \n",
        "else:\n",
        "  mini = np.amin(x_train[:])\n",
        "  maxi = np.amax(x_train[:])\n",
        "  \n",
        "  x_train = (x_train - mini ) /(maxi-mini)\n",
        "  x_test  = (x_test - mini ) /(maxi-mini)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUHDuTNuO-n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Wsquare = int(4)\n",
        "Nsquare = int(3)\n",
        "\n",
        "# generate missing data areas for training data\n",
        "x_train_missing = np.copy(x_train).astype(float)\n",
        "mask_train      = np.zeros((x_train.shape))\n",
        "mask_test       = np.zeros((x_test.shape))\n",
        "\n",
        "for ii in range(x_train.shape[0]):\n",
        "  # generate mask\n",
        "  mask   = np.ones((x_train.shape[1],x_train.shape[2])).astype(float)\n",
        "  i_area = np.floor(np.random.uniform(Wsquare,x_train.shape[1]-Wsquare,Nsquare)).astype(int)\n",
        "  j_area = np.floor(np.random.uniform(Wsquare,x_train.shape[2]-Wsquare,Nsquare)).astype(int)\n",
        "  \n",
        "  for nn in range(Nsquare):\n",
        "    mask[i_area[nn]-Wsquare:i_area[nn]+Wsquare+1,j_area[nn]-Wsquare:j_area[nn]+Wsquare+1] = 0.\n",
        "    \n",
        "  # apply mask\n",
        "  x_train_missing[ii,:,:] *= mask\n",
        "  mask_train[ii,:,:]       = mask     \n",
        "  \n",
        "## generate missing data areas for test data\n",
        "x_test_missing = np.copy(x_test).astype(float)\n",
        "\n",
        "for ii in range(x_test.shape[0]):\n",
        "  # generate mask\n",
        "  mask   = np.ones((x_test.shape[1],x_test.shape[2])).astype(float)\n",
        "  i_area = np.floor(np.random.uniform(Wsquare,x_test.shape[1]-Wsquare,Nsquare)).astype(int)\n",
        "  j_area = np.floor(np.random.uniform(Wsquare,x_test.shape[2]-Wsquare,Nsquare)).astype(int)\n",
        "  \n",
        "  for nn in range(Nsquare):\n",
        "    mask[i_area[nn]-Wsquare:i_area[nn]+Wsquare+1,j_area[nn]-Wsquare:j_area[nn]+Wsquare+1] = 0.\n",
        "    \n",
        "  # apply mask\n",
        "  x_test_missing[ii,:,:] *= mask\n",
        "  mask_test[ii,:,:]      = mask     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on6EitLoPOtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random selection of indices for visualization\n",
        "indexes_train = np.random.permutation(x_train.shape[0])\n",
        "indexes_test  = np.random.permutation(x_test.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3BsJarQPdYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "96f81685-ba95-48a1-a30d-a443ee358fd4"
      },
      "source": [
        "# visualize missing data pattern for training data\n",
        "plt.figure()\n",
        "for ii in range(5):\n",
        "    plt.subplot(2, 5, ii + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(x_train[indexes_train[ii],:,:], cmap=plt.cm.gray_r)\n",
        "    plt.title('GT:%i' %(y_train[indexes_train[ii]]))\n",
        "    plt.subplot(2, 5, ii + 1+5)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(x_train_missing[indexes_train[ii],:,:], cmap=plt.cm.gray_r)\n",
        "plt.show()\n",
        "\n",
        "# visualize missing data pattern for test data\n",
        "plt.figure()\n",
        "for ii in range(5):\n",
        "    plt.subplot(2, 5, ii + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(x_test[indexes_test[ii],:,:], cmap=plt.cm.gray_r)\n",
        "    plt.title('GT:%i' %(y_test[indexes_test[ii]]))\n",
        "    plt.subplot(2, 5, ii + 1+5)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(x_test_missing[indexes_test[ii],:,:], cmap=plt.cm.gray_r)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADOCAYAAACdDdHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFApFQP5/Q7gateA78lYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADOCAYAAACdDdHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLoVCoRSR/wGfDKHqZuz7bwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EalHW7NPCui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ntr = 10000\n",
        "Ntt = 5000\n",
        "\n",
        "x_train = x_train[indexes_train[0:Ntr],:,:]\n",
        "y_train = y_train[indexes_train[0:Ntr]]\n",
        "x_train_missing = x_train_missing[indexes_train[0:Ntr],:,:]\n",
        "mask_train = mask_train[indexes_train[0:Ntr],:,:]\n",
        "\n",
        "x_test  = x_test[indexes_test[0:Ntt],:,:]\n",
        "y_test  = y_test[indexes_test[0:Ntt]]\n",
        "x_test_missing = x_test_missing[indexes_test[0:Ntt],:,:]\n",
        "mask_test = mask_test[indexes_test[0:Ntt],:,:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfj4X9p88js9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train         = x_train.reshape((x_train.shape[0],1,x_train.shape[1],x_train.shape[2]))\n",
        "x_train_missing = x_train_missing.reshape((x_train_missing.shape[0],1,x_train.shape[2],x_train.shape[3]))\n",
        "mask_train      = mask_train.reshape((x_train.shape[0],1,x_train.shape[2],x_train.shape[3]))\n",
        "\n",
        "x_test         = x_test.reshape((x_test.shape[0],1,x_test.shape[1],x_test.shape[2]))\n",
        "x_test_missing = x_test_missing.reshape((x_test.shape[0],1,x_test.shape[2],x_test.shape[3]))\n",
        "mask_test      = mask_test.reshape((x_test.shape[0],1,x_test.shape[2],x_test.shape[3]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz9jt7vhdSNg",
        "colab_type": "text"
      },
      "source": [
        "# PCA Decomposition & AE artchitecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBmY_dJodiTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DimAE      = 20#50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcxDm4jgPwUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "34dc4261-70d0-407d-aaec-ab536552d953"
      },
      "source": [
        "# PCA decomposition\n",
        "pca              = decomposition.PCA(DimAE)\n",
        "pca.fit(np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]*x_train.shape[3])))\n",
        "\n",
        "rec_PCA_Tt       = pca.transform(np.reshape(x_test,(x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3])))\n",
        "rec_PCA_Tt[:,DimAE:] = 0.\n",
        "rec_PCA_Tt       = pca.inverse_transform(rec_PCA_Tt)\n",
        "mse_PCA_Tt       = np.mean( (rec_PCA_Tt - x_test.reshape((x_test.shape[0],x_test.shape[1]*x_test.shape[2]*x_test.shape[3])))**2 )\n",
        "var_Tt           = np.mean( (x_test-np.mean(x_train,axis=0))** 2 )\n",
        "exp_var_PCA_Tt   = 1. - mse_PCA_Tt / var_Tt\n",
        "\n",
        "print(\".......... PCA Dim = %d\"%(DimAE))\n",
        "print('.... explained variance PCA (Tr) : %.2f%%'%(100.*np.cumsum(pca.explained_variance_ratio_)[DimAE-1]))\n",
        "print('.... explained variance PCA (Tt) : %.2f%%'%(100.*exp_var_PCA_Tt))\n",
        "\n",
        "# visualize PCs and associated projection\n",
        "PC              = np.zeros((DimAE+1,x_test.shape[1]*x_test.shape[2]*x_test.shape[3])) * float('NaN')                        \n",
        "PC[1:DimAE+1,:] = pca.components_\n",
        "PC[0,:]         = pca.mean_\n",
        "PC              = np.reshape(PC,(DimAE+1,x_test.shape[1],x_test.shape[2],x_test.shape[3]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......... PCA Dim = 20\n",
            ".... explained variance PCA (Tr) : 64.54%\n",
            ".... explained variance PCA (Tt) : 65.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0kw3EDW5tFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNetConv2D(torch.nn.Module):\n",
        "  def __init__(self,Nblocks,dim,K,\n",
        "                 kernel_size,\n",
        "                 padding=0):\n",
        "      super(ResNetConv2D, self).__init__()\n",
        "      self.resnet = self._make_ResNet(Nblocks,dim,K,kernel_size,padding)\n",
        "\n",
        "  def _make_ResNet(self,Nblocks,dim,K,kernel_size,padding):\n",
        "      layers = []\n",
        "      for kk in range(0,Nblocks):\n",
        "        layers.append(torch.nn.Conv2d(dim,K*dim,kernel_size,padding=padding,bias=False))\n",
        "        layers.append(torch.nn.Conv2d(K*dim,dim,kernel_size,padding=padding,bias=False))\n",
        "\n",
        "      return torch.nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.resnet ( x )\n",
        "\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCbFN667BMRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "39d395c3-10d6-4c2a-d71d-28a0249fa316"
      },
      "source": [
        "resnet = ResNetConv2D(2,1,5,3,1)\n",
        "print(resnet)\n",
        "print('Number of trainable parameters = %d'%(sum(p.numel() for p in model_AE.parameters() if p.requires_grad)))\n",
        "\n",
        "#Model visualisation\n",
        "inputs = torch.randn(21,1,28,28)\n",
        "y = resnet(torch.autograd.Variable(inputs))\n",
        "print(y.size())\n",
        "torchviz.make_dot(y)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNetConv2D(\n",
            "  (resnet): Sequential(\n",
            "    (0): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (3): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters = 248380\n",
            "torch.Size([21, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f6f0e7297b8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"392pt\" height=\"313pt\"\n viewBox=\"0.00 0.00 391.50 313.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 309)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-309 387.5,-309 387.5,4 -4,4\"/>\n<!-- 140114960490448 -->\n<g id=\"node1\" class=\"node\">\n<title>140114960490448</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"363,-21 201,-21 201,0 363,0 363,-21\"/>\n<text text-anchor=\"middle\" x=\"282\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 140114960487704 -->\n<g id=\"node2\" class=\"node\">\n<title>140114960487704</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"296,-85 134,-85 134,-64 296,-64 296,-85\"/>\n<text text-anchor=\"middle\" x=\"215\" y=\"-71.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 140114960487704&#45;&gt;140114960490448 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140114960487704&#45;&gt;140114960490448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M226.0637,-63.9317C236.1861,-54.2625 251.3665,-39.7619 263.3599,-28.3054\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"265.8824,-30.7362 270.6959,-21.2979 261.0472,-25.6744 265.8824,-30.7362\"/>\n</g>\n<!-- 140115255795272 -->\n<g id=\"node3\" class=\"node\">\n<title>140115255795272</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"229,-156 67,-156 67,-135 229,-135 229,-156\"/>\n<text text-anchor=\"middle\" x=\"148\" y=\"-142.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 140115255795272&#45;&gt;140114960487704 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140115255795272&#45;&gt;140114960487704</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M158.1759,-134.7166C168.6044,-123.6655 185.0196,-106.2703 197.5311,-93.0118\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.4107,-95.06 204.7284,-85.3849 195.3196,-90.2557 200.4107,-95.06\"/>\n</g>\n<!-- 140115255795664 -->\n<g id=\"node4\" class=\"node\">\n<title>140115255795664</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-227 0,-227 0,-206 162,-206 162,-227\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-213.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 140115255795664&#45;&gt;140115255795272 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140115255795664&#45;&gt;140115255795272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M91.1759,-205.7166C101.6044,-194.6655 118.0196,-177.2703 130.5311,-164.0118\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.4107,-166.06 137.7284,-156.3849 128.3196,-161.2557 133.4107,-166.06\"/>\n</g>\n<!-- 140115255820472 -->\n<g id=\"node5\" class=\"node\">\n<title>140115255820472</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"115.5,-305 46.5,-305 46.5,-270 115.5,-270 115.5,-305\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-277.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (5, 1, 3, 3)</text>\n</g>\n<!-- 140115255820472&#45;&gt;140115255795664 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140115255820472&#45;&gt;140115255795664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M81,-269.9494C81,-260.058 81,-247.6435 81,-237.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-237.0288 81,-227.0288 77.5001,-237.0289 84.5001,-237.0288\"/>\n</g>\n<!-- 140115255820360 -->\n<g id=\"node6\" class=\"node\">\n<title>140115255820360</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"249.5,-234 180.5,-234 180.5,-199 249.5,-199 249.5,-234\"/>\n<text text-anchor=\"middle\" x=\"215\" y=\"-206.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 5, 3, 3)</text>\n</g>\n<!-- 140115255820360&#45;&gt;140115255795272 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140115255820360&#45;&gt;140115255795272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M198.4382,-198.9494C188.2103,-188.1109 175.1238,-174.2431 164.844,-163.3496\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.3445,-160.8997 157.9357,-156.0288 162.2534,-165.704 167.3445,-160.8997\"/>\n</g>\n<!-- 140115255795552 -->\n<g id=\"node7\" class=\"node\">\n<title>140115255795552</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"316.5,-163 247.5,-163 247.5,-128 316.5,-128 316.5,-163\"/>\n<text text-anchor=\"middle\" x=\"282\" y=\"-135.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (5, 1, 3, 3)</text>\n</g>\n<!-- 140115255795552&#45;&gt;140114960487704 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140115255795552&#45;&gt;140114960487704</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M265.4382,-127.9494C255.2103,-117.1109 242.1238,-103.2431 231.844,-92.3496\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.3445,-89.8997 224.9357,-85.0288 229.2534,-94.704 234.3445,-89.8997\"/>\n</g>\n<!-- 140115255794936 -->\n<g id=\"node8\" class=\"node\">\n<title>140115255794936</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"383.5,-92 314.5,-92 314.5,-57 383.5,-57 383.5,-92\"/>\n<text text-anchor=\"middle\" x=\"349\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 5, 3, 3)</text>\n</g>\n<!-- 140115255794936&#45;&gt;140114960490448 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140115255794936&#45;&gt;140114960490448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M330.3368,-56.6724C321.0197,-47.7726 309.7839,-37.0398 300.4907,-28.1628\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"302.8748,-25.5999 293.2261,-21.2234 298.0396,-30.6617 302.8748,-25.5999\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lds7AJfYYavr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "198cfc06-0dde-4391-91c5-7bafc037d2ee"
      },
      "source": [
        "flagAEType = 1\n",
        "dropout = 0.05\n",
        "wl2     = 0\n",
        "shapeData = x_train.shape[1:]\n",
        "\n",
        "if flagAEType == 0: ## MLP-AE\n",
        "\n",
        "  class Encoder(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Encoder, self).__init__()\n",
        "          self.fc1 = torch.nn.Linear(shapeData[0]*shapeData[1]*shapeData[2],6*DimAE)\n",
        "          self.fc2 = torch.nn.Linear(6*DimAE,2*DimAE)\n",
        "          self.fc3 = torch.nn.Linear(2*DimAE,DimAE)\n",
        "\n",
        "      def forward(self, x):\n",
        "          #x = self.fc1( torch.nn.Flatten(x) )\n",
        "          x = self.fc1( x.view(-1,shapeData[0]*shapeData[1]*shapeData[2]) )\n",
        "          x = self.fc2( F.relu(x) )\n",
        "          x = self.fc3( F.relu(x) )\n",
        "          return x\n",
        "\n",
        "  encoder = Encoder()\n",
        "\n",
        "  class Decoder(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Decoder, self).__init__()\n",
        "          self.fc1 = torch.nn.Linear(DimAE,10*DimAE)\n",
        "          self.fc2 = torch.nn.Linear(10*DimAE,20*DimAE)\n",
        "          self.fc3 = torch.nn.Linear(20*DimAE,shapeData[0]*shapeData[1]*shapeData[2])\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = self.fc1( x )\n",
        "          x = self.fc2( F.relu(x) )\n",
        "          x = self.fc3( F.relu(x) )\n",
        "          x = x.view(-1,shapeData[0],shapeData[1],shapeData[2])\n",
        "          return x\n",
        "\n",
        "elif flagAEType == 1: ## Conv-AE\n",
        "  Wpool_i = np.floor(  (np.floor((x_train.shape[2]-2)/2)-2)/2 ).astype(int) \n",
        "  Wpool_j = np.floor(  (np.floor((x_train.shape[3]-2)/2)-2)/2 ).astype(int)\n",
        "\n",
        "  class Encoder(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Encoder, self).__init__()\n",
        "          self.conv1 = torch.nn.Conv2d(shapeData[0],DimAE,(3,3),padding=0)\n",
        "          self.pool1 = torch.nn.AvgPool2d((2,2))\n",
        "          self.conv2 = torch.nn.Conv2d(DimAE,2*DimAE,(3,3),padding=0)\n",
        "          self.pool2 = torch.nn.AvgPool2d((2,2))\n",
        "          self.conv3 = torch.nn.Conv2d(2*DimAE,4*DimAE,(Wpool_i,Wpool_j),padding=0)\n",
        "          self.conv4 = torch.nn.Conv2d(4*DimAE,DimAE,(1,1),padding=0)\n",
        "\n",
        "      def forward(self, x):\n",
        "          #x = self.fc1( torch.nn.Flatten(x) )\n",
        "          x = self.conv1( x )\n",
        "          x = self.pool1(x)\n",
        "          x = self.conv2( F.relu(x) )\n",
        "          x = self.pool2(x)\n",
        "          x = self.conv3( F.relu(x) )\n",
        "          x = self.conv4( F.relu(x) )\n",
        "          x = x.view(-1,DimAE)\n",
        "          return x\n",
        "\n",
        "  class Decoder(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Decoder, self).__init__()\n",
        "          #self.conv1Tr = torch.nn.ConvTranspose2d(DimAE,1,(x_train.shape[1],x_train.shape[2]),stride=(x_train.shape[1],x_train.shape[2]),bias=False)\n",
        "          self.conv1Tr = torch.nn.ConvTranspose2d(DimAE,DimAE,(int(x_train.shape[2]/2),int(x_train.shape[3]/2)),stride=(int(x_train.shape[2]/2),int(x_train.shape[3]/2)),bias=False)\n",
        "          self.conv11   = torch.nn.Conv2d(DimAE,DimAE,(3,3),padding=1)\n",
        "          self.conv12   = torch.nn.Conv2d(DimAE,DimAE,(3,3),padding=1)\n",
        "          self.conv2Tr = torch.nn.ConvTranspose2d(DimAE,DimAE,(2,2),stride=(2,2),bias=False)\n",
        "          #self.resnet  = self._make_ResNet(2,DimAE,5,3,1)\n",
        "          self.resnet = dinAE.ResNetConv2D(2,DimAE,5,3,1)\n",
        "          self.convF   = torch.nn.Conv2d(DimAE,1,(1,1),padding=0)\n",
        "      def _make_ResNet(self,Nblocks,dim,K,kernel_size, padding):\n",
        "          layers = []\n",
        "          for kk in range(0,Nblocks):\n",
        "            layers.append(torch.nn.Conv2d(dim,K*dim,kernel_size,padding=padding,bias=False))\n",
        "            layers.append(torch.nn.Conv2d(K*dim,dim,kernel_size,padding=padding,bias=False))\n",
        "\n",
        "          return torch.nn.Sequential(*layers)\n",
        "\n",
        "      def forward(self, x):\n",
        "          x = x.view(-1,DimAE,1,1)\n",
        "          x = self.conv1Tr( x )\n",
        "          x = torch.add(self.conv12( F.relu( self.conv11(x) ) ),x)\n",
        "          x = torch.add(self.conv12( F.relu( self.conv11(x) ) ),x)\n",
        "          x = self.conv2Tr( x )\n",
        "          x = self.resnet(x)\n",
        "          x = self.convF(x)\n",
        "\n",
        "          #x = torch.add(self.conv22( F.relu( self.conv21(x) ) ),x)\n",
        "          #x = torch.add(self.conv22( F.relu( self.conv21(x) ) ),x)\n",
        "          #x = self.conv3( x )\n",
        "          #x = x.view(-1,shapeData[0],shapeData[1],shapeData[2])\n",
        "          return x\n",
        "\n",
        "elif flagAEType == 2: ## Conv model with no use of the central point\n",
        "  Wpool_i = np.floor(  (np.floor((x_train.shape[1]-2)/2)-2)/2 ).astype(int) \n",
        "  Wpool_j = np.floor(  (np.floor((x_train.shape[2]-2)/2)-2)/2 ).astype(int)\n",
        "\n",
        "  class Encoder(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Encoder, self).__init__()\n",
        "          self.pool1 = torch.nn.AvgPool2d((2,2))\n",
        "          self.conv1 = dinAE.ConstrainedConv2d(shapeData[0],shapeData[0]*DimAE,(3,3),padding=1)\n",
        "          self.conv2 = torch.nn.Conv2d(shapeData[0]*DimAE,2*shapeData[0]*DimAE,(1,1),padding=0)\n",
        "          self.conv3 = torch.nn.Conv2d(2*shapeData[0]*DimAE,4*shapeData[0]*DimAE,(1,1),padding=0)\n",
        "          self.conv4 = torch.nn.Conv2d(4*shapeData[0]*DimAE,8*shapeData[0]*DimAE,(1,1),padding=0)\n",
        "          self.conv2Tr = torch.nn.ConvTranspose2d(8*shapeData[0]*DimAE,8*shapeData[0]*DimAE,(2,2),stride=(2,2),bias=False)          \n",
        "          self.conv5 = torch.nn.Conv2d(8*shapeData[0]*DimAE,16*shapeData[0]*DimAE,(3,3),padding=1)\n",
        "          self.conv6 = torch.nn.Conv2d(16*shapeData[0]*DimAE,1,(3,3),padding=1)\n",
        "\n",
        "      def forward(self, x):\n",
        "          #x = self.fc1( torch.nn.Flatten(x) )\n",
        "          x = self.pool1( x )\n",
        "          x = self.conv1(x)\n",
        "          x = self.conv2( F.relu(x) )\n",
        "          x = self.conv3( F.relu(x) )\n",
        "          x = self.conv4( F.relu(x) )\n",
        "          x = self.conv2Tr( x )\n",
        "          x = self.conv5( x )\n",
        "          x = self.conv6( x )\n",
        "          x = x.view(-1,shapeData[0],shapeData[1],shapeData[2])\n",
        "          return x\n",
        "\n",
        "  class Decoder(torch.nn.Module):\n",
        "      def __init__(self):\n",
        "          super(Decoder, self).__init__()\n",
        "\n",
        "      def forward(self, x):\n",
        "          return torch.mul(1.,x)\n",
        "\n",
        "class Model_AE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model_AE, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder( x )\n",
        "        x = self.decoder( x )\n",
        "        return x\n",
        "\n",
        "model_AE = Model_AE()\n",
        "\n",
        "print(model_AE)\n",
        "print('Number of trainable parameters = %d'%(sum(p.numel() for p in model_AE.parameters() if p.requires_grad)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model_AE(\n",
            "  (encoder): Encoder(\n",
            "    (conv1): Conv2d(1, 20, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (pool1): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "    (conv2): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (pool2): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
            "    (conv3): Conv2d(40, 80, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (conv4): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (conv1Tr): ConvTranspose2d(20, 20, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
            "    (conv11): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv12): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2Tr): ConvTranspose2d(20, 20, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (resnet): ResNetConv2D(\n",
            "      (resnet): Sequential(\n",
            "        (0): Conv2d(20, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): Conv2d(100, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (2): Conv2d(20, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (3): Conv2d(100, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (convF): Conv2d(20, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Number of trainable parameters = 248401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSHRMru9Ypwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26835925-bf75-45b0-a04c-2b450c84dcd8"
      },
      "source": [
        "#Model visualisation\n",
        "inputs = torch.randn(21,1,28,28)\n",
        "y = model_AE(torch.autograd.Variable(inputs))\n",
        "print(y.size())\n",
        "torchviz.make_dot(y)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([21, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f158805dfd0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"742pt\" height=\"1048pt\"\n viewBox=\"0.00 0.00 741.59 1048.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.619 .619) rotate(0) translate(4 1689)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1689 1194,-1689 1194,4 -4,4\"/>\n<!-- 139730388914072 -->\n<g id=\"node1\" class=\"node\">\n<title>139730388914072</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"1161,-21 999,-21 999,0 1161,0 1161,-21\"/>\n<text text-anchor=\"middle\" x=\"1080\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730388913288 -->\n<g id=\"node2\" class=\"node\">\n<title>139730388913288</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1024,-85 862,-85 862,-64 1024,-64 1024,-85\"/>\n<text text-anchor=\"middle\" x=\"943\" y=\"-71.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730388913288&#45;&gt;139730388914072 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139730388913288&#45;&gt;139730388914072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M965.6228,-63.9317C988.1311,-53.4168 1022.8703,-37.1883 1048.1593,-25.3745\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1049.7649,-28.4876 1057.3436,-21.084 1046.8021,-22.1455 1049.7649,-28.4876\"/>\n</g>\n<!-- 139730388913232 -->\n<g id=\"node3\" class=\"node\">\n<title>139730388913232</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"953,-156 791,-156 791,-135 953,-135 953,-156\"/>\n<text text-anchor=\"middle\" x=\"872\" y=\"-142.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730388913232&#45;&gt;139730388913288 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139730388913232&#45;&gt;139730388913288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M882.7834,-134.7166C893.9388,-123.5612 911.5585,-105.9415 924.8623,-92.6377\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"927.5189,-94.9308 932.1151,-85.3849 922.5692,-89.9811 927.5189,-94.9308\"/>\n</g>\n<!-- 139730388913736 -->\n<g id=\"node4\" class=\"node\">\n<title>139730388913736</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"882,-227 720,-227 720,-206 882,-206 882,-227\"/>\n<text text-anchor=\"middle\" x=\"801\" y=\"-213.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730388913736&#45;&gt;139730388913232 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139730388913736&#45;&gt;139730388913232</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M811.7834,-205.7166C822.9388,-194.5612 840.5585,-176.9415 853.8623,-163.6377\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"856.5189,-165.9308 861.1151,-156.3849 851.5692,-160.9811 856.5189,-165.9308\"/>\n</g>\n<!-- 139730388913512 -->\n<g id=\"node5\" class=\"node\">\n<title>139730388913512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"811,-298 649,-298 649,-277 811,-277 811,-298\"/>\n<text text-anchor=\"middle\" x=\"730\" y=\"-284.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730388913512&#45;&gt;139730388913736 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139730388913512&#45;&gt;139730388913736</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M740.7834,-276.7166C751.9388,-265.5612 769.5585,-247.9415 782.8623,-234.6377\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"785.5189,-236.9308 790.1151,-227.3849 780.5692,-231.9811 785.5189,-236.9308\"/>\n</g>\n<!-- 139730500483952 -->\n<g id=\"node6\" class=\"node\">\n<title>139730500483952</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"744.5,-369 565.5,-369 565.5,-348 744.5,-348 744.5,-369\"/>\n<text text-anchor=\"middle\" x=\"655\" y=\"-355.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SlowConvTranspose2DBackward</text>\n</g>\n<!-- 139730500483952&#45;&gt;139730388913512 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139730500483952&#45;&gt;139730388913512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M666.3909,-347.7166C678.2849,-336.457 697.1356,-318.6116 711.2333,-305.2658\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"713.646,-307.8014 718.5019,-298.3849 708.8336,-302.7179 713.646,-307.8014\"/>\n</g>\n<!-- 139730500483616 -->\n<g id=\"node7\" class=\"node\">\n<title>139730500483616</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"649,-440 557,-440 557,-419 649,-419 649,-440\"/>\n<text text-anchor=\"middle\" x=\"603\" y=\"-426.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139730500483616&#45;&gt;139730500483952 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139730500483616&#45;&gt;139730500483952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M610.8977,-418.7166C618.8388,-407.874 631.2525,-390.9244 640.8892,-377.7667\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"643.9429,-379.5206 647.028,-369.3849 638.2956,-375.3845 643.9429,-379.5206\"/>\n</g>\n<!-- 139730500483504 -->\n<g id=\"node8\" class=\"node\">\n<title>139730500483504</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"739,-504 577,-504 577,-483 739,-483 739,-504\"/>\n<text text-anchor=\"middle\" x=\"658\" y=\"-490.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730500483504&#45;&gt;139730500483616 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139730500483504&#45;&gt;139730500483616</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M648.9179,-482.9317C640.7667,-473.4467 628.6201,-459.3125 618.8669,-447.9634\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"621.4516,-445.6009 612.2795,-440.2979 616.1427,-450.1633 621.4516,-445.6009\"/>\n</g>\n<!-- 139730500483784 -->\n<g id=\"node9\" class=\"node\">\n<title>139730500483784</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"797,-561 703,-561 703,-540 797,-540 797,-561\"/>\n<text text-anchor=\"middle\" x=\"750\" y=\"-547.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139730500483784&#45;&gt;139730500483504 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139730500483784&#45;&gt;139730500483504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M732.6955,-539.7787C718.9459,-531.26 699.5012,-519.2127 683.8979,-509.5454\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"685.571,-506.4647 675.2269,-504.1732 681.8842,-512.4152 685.571,-506.4647\"/>\n</g>\n<!-- 139730500483000 -->\n<g id=\"node10\" class=\"node\">\n<title>139730500483000</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"848,-618 686,-618 686,-597 848,-597 848,-618\"/>\n<text text-anchor=\"middle\" x=\"767\" y=\"-604.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730500483000&#45;&gt;139730500483784 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139730500483000&#45;&gt;139730500483784</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M763.8024,-596.7787C761.6417,-589.5338 758.7197,-579.7367 756.1206,-571.0221\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"759.3954,-569.7557 753.1832,-561.1732 752.6873,-571.7564 759.3954,-569.7557\"/>\n</g>\n<!-- 139730500483840 -->\n<g id=\"node11\" class=\"node\">\n<title>139730500483840</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"595,-675 503,-675 503,-654 595,-654 595,-675\"/>\n<text text-anchor=\"middle\" x=\"549\" y=\"-661.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139730500483840&#45;&gt;139730500483616 -->\n<g id=\"edge44\" class=\"edge\">\n<title>139730500483840&#45;&gt;139730500483616</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M548.4056,-653.8882C547.1619,-625.3226 546.0168,-544.7889 568,-483 572.4436,-470.5103 580.3593,-458.0294 587.5401,-448.2677\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"590.4696,-450.2004 593.8074,-440.1451 584.9275,-445.9242 590.4696,-450.2004\"/>\n</g>\n<!-- 139730500483840&#45;&gt;139730500483000 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139730500483840&#45;&gt;139730500483000</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M589.2386,-653.9789C625.1519,-644.5887 677.8977,-630.7974 716.6078,-620.6759\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"717.8378,-623.9721 726.6272,-618.0562 716.067,-617.1997 717.8378,-623.9721\"/>\n</g>\n<!-- 139730500482888 -->\n<g id=\"node12\" class=\"node\">\n<title>139730500482888</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"630,-732 468,-732 468,-711 630,-711 630,-732\"/>\n<text text-anchor=\"middle\" x=\"549\" y=\"-718.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730500482888&#45;&gt;139730500483840 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139730500482888&#45;&gt;139730500483840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M549,-710.7787C549,-703.6134 549,-693.9517 549,-685.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"552.5001,-685.1732 549,-675.1732 545.5001,-685.1732 552.5001,-685.1732\"/>\n</g>\n<!-- 139730453569608 -->\n<g id=\"node13\" class=\"node\">\n<title>139730453569608</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"597,-796 503,-796 503,-775 597,-775 597,-796\"/>\n<text text-anchor=\"middle\" x=\"550\" y=\"-782.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139730453569608&#45;&gt;139730500482888 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139730453569608&#45;&gt;139730500482888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M549.8349,-774.9317C549.6967,-766.0913 549.4955,-753.2122 549.3252,-742.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"552.8246,-742.242 549.1687,-732.2979 545.8255,-742.3514 552.8246,-742.242\"/>\n</g>\n<!-- 139730453569664 -->\n<g id=\"node14\" class=\"node\">\n<title>139730453569664</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"668,-860 506,-860 506,-839 668,-839 668,-860\"/>\n<text text-anchor=\"middle\" x=\"587\" y=\"-846.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730453569664&#45;&gt;139730453569608 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139730453569664&#45;&gt;139730453569608</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M580.8902,-838.9317C575.5664,-829.723 567.7091,-816.1319 561.2514,-804.9619\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.2777,-803.2035 556.2425,-796.2979 558.2175,-806.7071 564.2777,-803.2035\"/>\n</g>\n<!-- 139730500482944 -->\n<g id=\"node15\" class=\"node\">\n<title>139730500482944</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"543.5,-924 364.5,-924 364.5,-903 543.5,-903 543.5,-924\"/>\n<text text-anchor=\"middle\" x=\"454\" y=\"-910.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SlowConvTranspose2DBackward</text>\n</g>\n<!-- 139730500482944&#45;&gt;139730500483840 -->\n<g id=\"edge39\" class=\"edge\">\n<title>139730500482944&#45;&gt;139730500483840</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M450.7596,-902.7589C441.762,-870.6775 419.6291,-773.896 459,-711 468.1187,-696.4326 483.3895,-686.211 498.787,-679.1401\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"500.4691,-682.23 508.3366,-675.134 497.7611,-675.775 500.4691,-682.23\"/>\n</g>\n<!-- 139730500482944&#45;&gt;139730453569664 -->\n<g id=\"edge14\" class=\"edge\">\n<title>139730500482944&#45;&gt;139730453569664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M475.9622,-902.9317C497.7172,-892.4632 531.2414,-876.3312 555.764,-864.5309\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"557.5118,-867.574 565.0051,-860.084 554.4765,-861.2663 557.5118,-867.574\"/>\n</g>\n<!-- 139730453569944 -->\n<g id=\"node16\" class=\"node\">\n<title>139730453569944</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"444.5,-995 353.5,-995 353.5,-974 444.5,-974 444.5,-995\"/>\n<text text-anchor=\"middle\" x=\"399\" y=\"-981.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 139730453569944&#45;&gt;139730500482944 -->\n<g id=\"edge15\" class=\"edge\">\n<title>139730453569944&#45;&gt;139730500482944</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M407.3533,-973.7166C415.8333,-962.7697 429.1354,-945.5979 439.3683,-932.3882\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"442.211,-934.4338 445.5681,-924.3849 436.6771,-930.147 442.211,-934.4338\"/>\n</g>\n<!-- 139730453570056 -->\n<g id=\"node17\" class=\"node\">\n<title>139730453570056</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"444.5,-1059 353.5,-1059 353.5,-1038 444.5,-1038 444.5,-1059\"/>\n<text text-anchor=\"middle\" x=\"399\" y=\"-1045.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 139730453570056&#45;&gt;139730453569944 -->\n<g id=\"edge16\" class=\"edge\">\n<title>139730453570056&#45;&gt;139730453569944</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M399,-1037.9317C399,-1029.0913 399,-1016.2122 399,-1005.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"402.5001,-1005.2979 399,-995.2979 395.5001,-1005.2979 402.5001,-1005.2979\"/>\n</g>\n<!-- 139730453570168 -->\n<g id=\"node18\" class=\"node\">\n<title>139730453570168</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"480,-1116 318,-1116 318,-1095 480,-1095 480,-1116\"/>\n<text text-anchor=\"middle\" x=\"399\" y=\"-1102.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730453570168&#45;&gt;139730453570056 -->\n<g id=\"edge17\" class=\"edge\">\n<title>139730453570168&#45;&gt;139730453570056</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M399,-1094.7787C399,-1087.6134 399,-1077.9517 399,-1069.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"402.5001,-1069.1732 399,-1059.1732 395.5001,-1069.1732 402.5001,-1069.1732\"/>\n</g>\n<!-- 139730453570280 -->\n<g id=\"node19\" class=\"node\">\n<title>139730453570280</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"340,-1180 246,-1180 246,-1159 340,-1159 340,-1180\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-1166.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139730453570280&#45;&gt;139730453570168 -->\n<g id=\"edge18\" class=\"edge\">\n<title>139730453570280&#45;&gt;139730453570168</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M310.5037,-1158.9317C327.4587,-1148.6948 353.3832,-1133.0422 372.7976,-1121.3203\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"374.7187,-1124.249 381.4703,-1116.084 371.1005,-1118.2565 374.7187,-1124.249\"/>\n</g>\n<!-- 139730453570504 -->\n<g id=\"node20\" class=\"node\">\n<title>139730453570504</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"374,-1244 212,-1244 212,-1223 374,-1223 374,-1244\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-1230.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730453570504&#45;&gt;139730453570280 -->\n<g id=\"edge19\" class=\"edge\">\n<title>139730453570504&#45;&gt;139730453570280</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293,-1222.9317C293,-1214.0913 293,-1201.2122 293,-1190.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-1190.2979 293,-1180.2979 289.5001,-1190.2979 296.5001,-1190.2979\"/>\n</g>\n<!-- 139730453570672 -->\n<g id=\"node21\" class=\"node\">\n<title>139730453570672</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"234,-1308 140,-1308 140,-1287 234,-1287 234,-1308\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-1294.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139730453570672&#45;&gt;139730453570504 -->\n<g id=\"edge20\" class=\"edge\">\n<title>139730453570672&#45;&gt;139730453570504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M204.5037,-1286.9317C221.4587,-1276.6948 247.3832,-1261.0422 266.7976,-1249.3203\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"268.7187,-1252.249 275.4703,-1244.084 265.1005,-1246.2565 268.7187,-1252.249\"/>\n</g>\n<!-- 139730453570896 -->\n<g id=\"node22\" class=\"node\">\n<title>139730453570896</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"248,-1372 126,-1372 126,-1351 248,-1351 248,-1372\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-1358.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AvgPool2DBackward</text>\n</g>\n<!-- 139730453570896&#45;&gt;139730453570672 -->\n<g id=\"edge21\" class=\"edge\">\n<title>139730453570896&#45;&gt;139730453570672</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187,-1350.9317C187,-1342.0913 187,-1329.2122 187,-1318.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5001,-1318.2979 187,-1308.2979 183.5001,-1318.2979 190.5001,-1318.2979\"/>\n</g>\n<!-- 139730453571120 -->\n<g id=\"node23\" class=\"node\">\n<title>139730453571120</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"268,-1429 106,-1429 106,-1408 268,-1408 268,-1429\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-1415.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730453571120&#45;&gt;139730453570896 -->\n<g id=\"edge22\" class=\"edge\">\n<title>139730453571120&#45;&gt;139730453570896</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187,-1407.7787C187,-1400.6134 187,-1390.9517 187,-1382.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5001,-1382.1732 187,-1372.1732 183.5001,-1382.1732 190.5001,-1382.1732\"/>\n</g>\n<!-- 139730453571624 -->\n<g id=\"node24\" class=\"node\">\n<title>139730453571624</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-1493 34,-1493 34,-1472 128,-1472 128,-1493\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-1479.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139730453571624&#45;&gt;139730453571120 -->\n<g id=\"edge23\" class=\"edge\">\n<title>139730453571624&#45;&gt;139730453571120</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M98.5037,-1471.9317C115.4587,-1461.6948 141.3832,-1446.0422 160.7976,-1434.3203\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.7187,-1437.249 169.4703,-1429.084 159.1005,-1431.2565 162.7187,-1437.249\"/>\n</g>\n<!-- 139730453571568 -->\n<g id=\"node25\" class=\"node\">\n<title>139730453571568</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"142,-1557 20,-1557 20,-1536 142,-1536 142,-1557\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-1543.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AvgPool2DBackward</text>\n</g>\n<!-- 139730453571568&#45;&gt;139730453571624 -->\n<g id=\"edge24\" class=\"edge\">\n<title>139730453571568&#45;&gt;139730453571624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M81,-1535.9317C81,-1527.0913 81,-1514.2122 81,-1503.3135\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-1503.2979 81,-1493.2979 77.5001,-1503.2979 84.5001,-1503.2979\"/>\n</g>\n<!-- 139730453571176 -->\n<g id=\"node26\" class=\"node\">\n<title>139730453571176</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-1614 0,-1614 0,-1593 162,-1593 162,-1614\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-1600.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139730453571176&#45;&gt;139730453571568 -->\n<g id=\"edge25\" class=\"edge\">\n<title>139730453571176&#45;&gt;139730453571568</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M81,-1592.7787C81,-1585.6134 81,-1575.9517 81,-1567.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-1567.1732 81,-1557.1732 77.5001,-1567.1732 84.5001,-1567.1732\"/>\n</g>\n<!-- 139730453571288 -->\n<g id=\"node27\" class=\"node\">\n<title>139730453571288</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-1685 2.5,-1685 2.5,-1650 77.5,-1650 77.5,-1685\"/>\n<text text-anchor=\"middle\" x=\"40\" y=\"-1657.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 1, 3, 3)</text>\n</g>\n<!-- 139730453571288&#45;&gt;139730453571176 -->\n<g id=\"edge26\" class=\"edge\">\n<title>139730453571288&#45;&gt;139730453571176</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M51.4208,-1649.6724C56.7802,-1641.3066 63.1771,-1631.3212 68.6488,-1622.7799\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"71.6831,-1624.5318 74.1303,-1614.2234 65.7889,-1620.7558 71.6831,-1624.5318\"/>\n</g>\n<!-- 139730453571064 -->\n<g id=\"node28\" class=\"node\">\n<title>139730453571064</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"150,-1685 96,-1685 96,-1650 150,-1650 150,-1685\"/>\n<text text-anchor=\"middle\" x=\"123\" y=\"-1657.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20)</text>\n</g>\n<!-- 139730453571064&#45;&gt;139730453571176 -->\n<g id=\"edge27\" class=\"edge\">\n<title>139730453571064&#45;&gt;139730453571176</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M111.3007,-1649.6724C105.8105,-1641.3066 99.2576,-1631.3212 93.6524,-1622.7799\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.45,-1620.6636 88.0373,-1614.2234 90.5977,-1624.5042 96.45,-1620.6636\"/>\n</g>\n<!-- 139730453571680 -->\n<g id=\"node29\" class=\"node\">\n<title>139730453571680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"227.5,-1500 146.5,-1500 146.5,-1465 227.5,-1465 227.5,-1500\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-1472.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (40, 20, 3, 3)</text>\n</g>\n<!-- 139730453571680&#45;&gt;139730453571120 -->\n<g id=\"edge28\" class=\"edge\">\n<title>139730453571680&#45;&gt;139730453571120</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187,-1464.6724C187,-1456.8405 187,-1447.5893 187,-1439.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5001,-1439.2234 187,-1429.2234 183.5001,-1439.2235 190.5001,-1439.2234\"/>\n</g>\n<!-- 139730453571456 -->\n<g id=\"node30\" class=\"node\">\n<title>139730453571456</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"300,-1500 246,-1500 246,-1465 300,-1465 300,-1500\"/>\n<text text-anchor=\"middle\" x=\"273\" y=\"-1472.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (40)</text>\n</g>\n<!-- 139730453571456&#45;&gt;139730453571120 -->\n<g id=\"edge29\" class=\"edge\">\n<title>139730453571456&#45;&gt;139730453571120</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M249.0442,-1464.6724C236.6462,-1455.446 221.6013,-1444.2498 209.4317,-1435.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.2694,-1432.1981 201.1575,-1429.0358 207.0903,-1437.8138 211.2694,-1432.1981\"/>\n</g>\n<!-- 139730453570616 -->\n<g id=\"node31\" class=\"node\">\n<title>139730453570616</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"333.5,-1315 252.5,-1315 252.5,-1280 333.5,-1280 333.5,-1315\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-1287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (80, 40, 5, 5)</text>\n</g>\n<!-- 139730453570616&#45;&gt;139730453570504 -->\n<g id=\"edge30\" class=\"edge\">\n<title>139730453570616&#45;&gt;139730453570504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293,-1279.6724C293,-1271.8405 293,-1262.5893 293,-1254.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-1254.2234 293,-1244.2234 289.5001,-1254.2235 296.5001,-1254.2234\"/>\n</g>\n<!-- 139730453570728 -->\n<g id=\"node32\" class=\"node\">\n<title>139730453570728</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"406,-1315 352,-1315 352,-1280 406,-1280 406,-1315\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-1287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (80)</text>\n</g>\n<!-- 139730453570728&#45;&gt;139730453570504 -->\n<g id=\"edge31\" class=\"edge\">\n<title>139730453570728&#45;&gt;139730453570504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M355.0442,-1279.6724C342.6462,-1270.446 327.6013,-1259.2498 315.4317,-1250.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"317.2694,-1247.1981 307.1575,-1244.0358 313.0903,-1252.8138 317.2694,-1247.1981\"/>\n</g>\n<!-- 139730453570392 -->\n<g id=\"node33\" class=\"node\">\n<title>139730453570392</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"439.5,-1187 358.5,-1187 358.5,-1152 439.5,-1152 439.5,-1187\"/>\n<text text-anchor=\"middle\" x=\"399\" y=\"-1159.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 80, 1, 1)</text>\n</g>\n<!-- 139730453570392&#45;&gt;139730453570168 -->\n<g id=\"edge32\" class=\"edge\">\n<title>139730453570392&#45;&gt;139730453570168</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M399,-1151.6724C399,-1143.8405 399,-1134.5893 399,-1126.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"402.5001,-1126.2234 399,-1116.2234 395.5001,-1126.2235 402.5001,-1126.2234\"/>\n</g>\n<!-- 139730453570448 -->\n<g id=\"node34\" class=\"node\">\n<title>139730453570448</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"512,-1187 458,-1187 458,-1152 512,-1152 512,-1187\"/>\n<text text-anchor=\"middle\" x=\"485\" y=\"-1159.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20)</text>\n</g>\n<!-- 139730453570448&#45;&gt;139730453570168 -->\n<g id=\"edge33\" class=\"edge\">\n<title>139730453570448&#45;&gt;139730453570168</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M461.0442,-1151.6724C448.6462,-1142.446 433.6013,-1131.2498 421.4317,-1122.1934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"423.2694,-1119.1981 413.1575,-1116.0358 419.0903,-1124.8138 423.2694,-1119.1981\"/>\n</g>\n<!-- 139730453570112 -->\n<g id=\"node35\" class=\"node\">\n<title>139730453570112</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"555.5,-1002 462.5,-1002 462.5,-967 555.5,-967 555.5,-1002\"/>\n<text text-anchor=\"middle\" x=\"509\" y=\"-974.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 20, 14, 14)</text>\n</g>\n<!-- 139730453570112&#45;&gt;139730500482944 -->\n<g id=\"edge34\" class=\"edge\">\n<title>139730453570112&#45;&gt;139730500482944</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M495.4045,-966.9494C487.1715,-956.3214 476.6821,-942.7806 468.3213,-931.9875\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"471.0471,-929.7909 462.1561,-924.0288 465.5132,-934.0778 471.0471,-929.7909\"/>\n</g>\n<!-- 139730500483168 -->\n<g id=\"node36\" class=\"node\">\n<title>139730500483168</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"657.5,-931 576.5,-931 576.5,-896 657.5,-896 657.5,-931\"/>\n<text text-anchor=\"middle\" x=\"617\" y=\"-903.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 20, 3, 3)</text>\n</g>\n<!-- 139730500483168&#45;&gt;139730500483000 -->\n<g id=\"edge40\" class=\"edge\">\n<title>139730500483168&#45;&gt;139730500483000</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M647.058,-895.9734C679.627,-874.4673 727,-834.7252 727,-785.5 727,-785.5 727,-785.5 727,-721.5 727,-686.7591 743.7445,-649.2513 755.5661,-627.0999\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"758.7857,-628.5109 760.5733,-618.068 752.6635,-625.1168 758.7857,-628.5109\"/>\n</g>\n<!-- 139730500483168&#45;&gt;139730453569664 -->\n<g id=\"edge35\" class=\"edge\">\n<title>139730500483168&#45;&gt;139730453569664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M608.6433,-895.6724C604.8053,-887.4845 600.24,-877.7453 596.2939,-869.327\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"599.4401,-867.7925 592.0266,-860.2234 593.1019,-870.7636 599.4401,-867.7925\"/>\n</g>\n<!-- 139730500483112 -->\n<g id=\"node37\" class=\"node\">\n<title>139730500483112</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"761,-931 707,-931 707,-896 761,-896 761,-931\"/>\n<text text-anchor=\"middle\" x=\"734\" y=\"-903.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20)</text>\n</g>\n<!-- 139730500483112&#45;&gt;139730500483000 -->\n<g id=\"edge41\" class=\"edge\">\n<title>139730500483112&#45;&gt;139730500483000</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M741.4219,-895.6235C750.875,-871.1968 766,-825.8148 766,-785.5 766,-785.5 766,-785.5 766,-721.5 766,-688.9909 766.4117,-651.2692 766.7067,-628.4062\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"770.2093,-628.2333 766.8438,-618.1872 763.2099,-628.1394 770.2093,-628.2333\"/>\n</g>\n<!-- 139730500483112&#45;&gt;139730453569664 -->\n<g id=\"edge36\" class=\"edge\">\n<title>139730500483112&#45;&gt;139730453569664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M706.6949,-901.6121C682.399,-891.0342 646.7779,-875.5257 620.7125,-864.1776\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"621.8,-860.8338 611.2342,-860.0509 619.0057,-867.2519 621.8,-860.8338\"/>\n</g>\n<!-- 139730500483336 -->\n<g id=\"node38\" class=\"node\">\n<title>139730500483336</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"697.5,-803 616.5,-803 616.5,-768 697.5,-768 697.5,-803\"/>\n<text text-anchor=\"middle\" x=\"657\" y=\"-775.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 20, 3, 3)</text>\n</g>\n<!-- 139730500483336&#45;&gt;139730500483504 -->\n<g id=\"edge42\" class=\"edge\">\n<title>139730500483336&#45;&gt;139730500483504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M657.237,-767.8662C657.5327,-744.3077 658,-701.2634 658,-664.5 658,-664.5 658,-664.5 658,-607.5 658,-574.9922 658,-537.2701 658,-514.4067\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"661.5001,-514.1875 658,-504.1875 654.5001,-514.1875 661.5001,-514.1875\"/>\n</g>\n<!-- 139730500483336&#45;&gt;139730500482888 -->\n<g id=\"edge37\" class=\"edge\">\n<title>139730500483336&#45;&gt;139730500482888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M627.2026,-767.8423C611.0229,-758.2543 591.1881,-746.5003 575.5429,-737.2291\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"577.262,-734.1795 566.8747,-732.0924 573.6933,-740.2015 577.262,-734.1795\"/>\n</g>\n<!-- 139730500483280 -->\n<g id=\"node39\" class=\"node\">\n<title>139730500483280</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"412,-803 358,-803 358,-768 412,-768 412,-803\"/>\n<text text-anchor=\"middle\" x=\"385\" y=\"-775.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20)</text>\n</g>\n<!-- 139730500483280&#45;&gt;139730500483504 -->\n<g id=\"edge43\" class=\"edge\">\n<title>139730500483280&#45;&gt;139730500483504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M386.8959,-767.8899C389.2616,-744.3577 393,-701.3424 393,-664.5 393,-664.5 393,-664.5 393,-607.5 393,-562.9837 520.7838,-525.3212 598.8831,-506.4598\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"600.1668,-509.7522 609.0861,-504.034 598.5477,-502.942 600.1668,-509.7522\"/>\n</g>\n<!-- 139730500483280&#45;&gt;139730500482888 -->\n<g id=\"edge38\" class=\"edge\">\n<title>139730500483280&#45;&gt;139730500482888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M412.0813,-774.9317C439.5004,-764.2316 482.0813,-747.6146 512.4738,-735.7541\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"513.8351,-738.98 521.8785,-732.084 511.2903,-732.459 513.8351,-738.98\"/>\n</g>\n<!-- 139730500482384 -->\n<g id=\"node40\" class=\"node\">\n<title>139730500482384</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"748.5,-447 667.5,-447 667.5,-412 748.5,-412 748.5,-447\"/>\n<text text-anchor=\"middle\" x=\"708\" y=\"-419.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 20, 2, 2)</text>\n</g>\n<!-- 139730500482384&#45;&gt;139730500483952 -->\n<g id=\"edge45\" class=\"edge\">\n<title>139730500482384&#45;&gt;139730500483952</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M694.8989,-411.9494C687.0438,-401.4266 677.0573,-388.0484 669.0404,-377.3089\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"671.6463,-374.9487 662.8596,-369.0288 666.0368,-379.1361 671.6463,-374.9487\"/>\n</g>\n<!-- 139730500483560 -->\n<g id=\"node41\" class=\"node\">\n<title>139730500483560</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"849.5,-376 762.5,-376 762.5,-341 849.5,-341 849.5,-376\"/>\n<text text-anchor=\"middle\" x=\"806\" y=\"-348.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (100, 20, 3, 3)</text>\n</g>\n<!-- 139730500483560&#45;&gt;139730388913512 -->\n<g id=\"edge46\" class=\"edge\">\n<title>139730500483560&#45;&gt;139730388913512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M787.2135,-340.9494C775.499,-330.0057 760.4788,-315.9736 748.7678,-305.0331\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"750.967,-302.2979 741.2703,-298.0288 746.1884,-307.4131 750.967,-302.2979\"/>\n</g>\n<!-- 139730500483672 -->\n<g id=\"node42\" class=\"node\">\n<title>139730500483672</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"916.5,-305 829.5,-305 829.5,-270 916.5,-270 916.5,-305\"/>\n<text text-anchor=\"middle\" x=\"873\" y=\"-277.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 100, 3, 3)</text>\n</g>\n<!-- 139730500483672&#45;&gt;139730388913736 -->\n<g id=\"edge47\" class=\"edge\">\n<title>139730500483672&#45;&gt;139730388913736</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M855.2022,-269.9494C844.2111,-259.1109 830.148,-245.2431 819.101,-234.3496\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"821.255,-231.5582 811.6771,-227.0288 816.34,-236.5424 821.255,-231.5582\"/>\n</g>\n<!-- 139730388914016 -->\n<g id=\"node43\" class=\"node\">\n<title>139730388914016</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"987.5,-234 900.5,-234 900.5,-199 987.5,-199 987.5,-234\"/>\n<text text-anchor=\"middle\" x=\"944\" y=\"-206.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (100, 20, 3, 3)</text>\n</g>\n<!-- 139730388914016&#45;&gt;139730388913232 -->\n<g id=\"edge48\" class=\"edge\">\n<title>139730388914016&#45;&gt;139730388913232</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M926.2022,-198.9494C915.2111,-188.1109 901.148,-174.2431 890.101,-163.3496\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"892.255,-160.5582 882.6771,-156.0288 887.34,-165.5424 892.255,-160.5582\"/>\n</g>\n<!-- 139730388913456 -->\n<g id=\"node44\" class=\"node\">\n<title>139730388913456</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1058.5,-163 971.5,-163 971.5,-128 1058.5,-128 1058.5,-163\"/>\n<text text-anchor=\"middle\" x=\"1015\" y=\"-135.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (20, 100, 3, 3)</text>\n</g>\n<!-- 139730388913456&#45;&gt;139730388913288 -->\n<g id=\"edge49\" class=\"edge\">\n<title>139730388913456&#45;&gt;139730388913288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M997.2022,-127.9494C986.2111,-117.1109 972.148,-103.2431 961.101,-92.3496\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"963.255,-89.5582 953.6771,-85.0288 958.34,-94.5424 963.255,-89.5582\"/>\n</g>\n<!-- 139730388913848 -->\n<g id=\"node45\" class=\"node\">\n<title>139730388913848</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1117.5,-92 1042.5,-92 1042.5,-57 1117.5,-57 1117.5,-92\"/>\n<text text-anchor=\"middle\" x=\"1080\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1, 20, 1, 1)</text>\n</g>\n<!-- 139730388913848&#45;&gt;139730388914072 -->\n<g id=\"edge50\" class=\"edge\">\n<title>139730388913848&#45;&gt;139730388914072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1080,-56.6724C1080,-48.8405 1080,-39.5893 1080,-31.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1083.5001,-31.2234 1080,-21.2234 1076.5001,-31.2235 1083.5001,-31.2234\"/>\n</g>\n<!-- 139730388913680 -->\n<g id=\"node46\" class=\"node\">\n<title>139730388913680</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1190,-92 1136,-92 1136,-57 1190,-57 1190,-92\"/>\n<text text-anchor=\"middle\" x=\"1163\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139730388913680&#45;&gt;139730388914072 -->\n<g id=\"edge51\" class=\"edge\">\n<title>139730388913680&#45;&gt;139730388914072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1139.8799,-56.6724C1127.9916,-47.5056 1113.5816,-36.3942 1101.8769,-27.3689\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1103.9633,-24.5581 1093.9069,-21.2234 1099.6889,-30.1015 1103.9633,-24.5581\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI5jYHQwd2tp",
        "colab_type": "text"
      },
      "source": [
        "# Learning AE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rq2cf5TZDRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training/test data pytorch tensors and associated  \n",
        "# list of tensors (xx[n][x] to access the nth sample for the xth field)\n",
        "training_dataset     = torch.utils.data.TensorDataset(torch.Tensor(x_train)) # create your datset\n",
        "test_dataset         = torch.utils.data.TensorDataset(torch.Tensor(x_test)) # create your datset\n",
        "\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True),\n",
        "    'val': torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True),\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(training_dataset), 'val': len(test_dataset)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVV21ui4ZIXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  use gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create a model from `AE` autoencoder class\n",
        "# load it to the specified device, either gpu or cpu\n",
        "model_AE  = model_AE.to(device)\n",
        "#model_AE.resnet = model_AE.decoder.resnet.to(device)\n",
        "\n",
        "# create an optimizer object\n",
        "# Adam optimizer with learning rate 1e-3\n",
        "optimizer        = optim.Adam(model_AE.parameters(), lr=1e-3)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "# mean-squared error loss\n",
        "criterion = torch.nn.MSELoss()\n",
        "var_Tr    = np.var( x_train )\n",
        "var_Tt    = np.var( x_test )\n",
        "\n",
        "# training function\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_var  = 0.0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs_ in dataloaders[phase]:\n",
        "                inputs = inputs_[0]\n",
        "                inputs = inputs.to(device)\n",
        "                #print(inputs.size(0))\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    #loss = criterion(outputs, inputs)\n",
        "                    loss = torch.mean((outputs - inputs)**2)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss   += loss.item() * inputs.size(0)\n",
        "                #running_expvar += torch.sum( (outputs - inputs)**2 ) / torch.sum(\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss  = running_loss / dataset_sizes[phase]\n",
        "            if phase == 'train':\n",
        "              epoch_nloss = epoch_loss / var_Tr\n",
        "            else:\n",
        "              epoch_nloss = epoch_loss / var_Tt\n",
        "            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} NLoss: {:.4f} '.format(\n",
        "                phase, epoch_loss, epoch_nloss))\n",
        "#            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "#                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf-la-loZOeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "4efe628e-3637-401c-c34e-d95278272ce3"
      },
      "source": [
        "# training AE model\n",
        "model_AE = train_model(model_AE, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=5)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 0.1761 NLoss: 0.1761 \n",
            "val Loss: 0.1030 NLoss: 0.1014 \n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.0956 NLoss: 0.0956 \n",
            "val Loss: 0.0887 NLoss: 0.0873 \n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 0.0862 NLoss: 0.0862 \n",
            "val Loss: 0.0823 NLoss: 0.0811 \n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 0.0809 NLoss: 0.0809 \n",
            "val Loss: 0.0809 NLoss: 0.0797 \n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.0776 NLoss: 0.0776 \n",
            "val Loss: 0.0755 NLoss: 0.0744 \n",
            "\n",
            "Training complete in 1m 60s\n",
            "Best val loss: 0.075512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuf9FiAYd9pJ",
        "colab_type": "text"
      },
      "source": [
        "# Learning AE model from irregularly-sampled data (DinAE model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfozh6kaZSai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training function for dinAE\n",
        "def train_model(model, optimizer, scheduler,alpha, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    alpha_MaskedLoss = alpha[0]\n",
        "    alpha_GTLoss     = 1. - alpha[0]\n",
        "    alpha_AE         = alpha[1]\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                #rint('Learning')\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                #print('Evaluation')\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_loss_All     = 0.\n",
        "            running_loss_R       = 0.\n",
        "            running_loss_I       = 0.\n",
        "            running_loss_AE      = 0.\n",
        "            num_loss     = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            #for inputs_ in dataloaders[phase]:\n",
        "            #    inputs = inputs_[0].to(device)\n",
        "            for inputs_missing,masks,inputs_GT in dataloaders[phase]:\n",
        "                inputs_missing = inputs_missing.to(device)\n",
        "                masks          = masks.to(device)\n",
        "                inputs_GT      = inputs_GT.to(device)\n",
        "                #print(inputs.size(0))\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # need to evaluate grad/backward during the evaluation and training phase for model_AE\n",
        "                with torch.set_grad_enabled(True): \n",
        "                #with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs_missing,masks)\n",
        "                    #outputs = model(inputs)\n",
        "                    #loss = criterion( outputs,  inputs)\n",
        "                    loss_R      = torch.sum((outputs - inputs_GT)**2 * masks )\n",
        "                    loss_R      = torch.mul(1.0 / torch.sum(masks),loss_R)\n",
        "                    loss_I      = torch.sum((outputs - inputs_GT)**2 * (1. - masks) )\n",
        "                    loss_I      = torch.mul(1.0 / torch.sum(1.-masks),loss_I)\n",
        "                    loss_All    = torch.mean((outputs - inputs_GT)**2 )\n",
        "                    loss_AE     = torch.mean((model.model_AE(outputs) - outputs)**2 )\n",
        "                    \n",
        "                    if alpha_MaskedLoss > 0.:\n",
        "                        loss = torch.mul(alpha_MaskedLoss,loss_R)\n",
        "                    else: \n",
        "                        loss = torch.mul(alpha_GTLoss,loss_All)\n",
        "                    loss = torch.add(loss,torch.mul(alpha_AE,loss_AE))\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss             += loss.item() * inputs_missing.size(0)\n",
        "                running_loss_I           += loss_I.item() * inputs_missing.size(0)\n",
        "                running_loss_R           += loss_R.item() * inputs_missing.size(0)\n",
        "                running_loss_All         += loss_All.item() * inputs_missing.size(0)\n",
        "                running_loss_AE          += loss_AE.item() * inputs_missing.size(0)\n",
        "                num_loss                 += inputs_missing.size(0)\n",
        "                #running_expvar += torch.sum( (outputs - inputs)**2 ) / torch.sum(\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss       = running_loss / num_loss\n",
        "            epoch_loss_All   = running_loss_All / num_loss\n",
        "            epoch_loss_AE    = running_loss_AE / num_loss\n",
        "            epoch_loss_I     = running_loss_I / num_loss\n",
        "            epoch_loss_R     = running_loss_R / num_loss\n",
        "            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            if phase == 'train':\n",
        "              epoch_nloss_All = epoch_loss_All / var_Tr\n",
        "              epoch_nloss_I   = epoch_loss_I / var_Tr\n",
        "              epoch_nloss_R   = epoch_loss_R / var_Tr\n",
        "              epoch_nloss_AE   = loss_AE / var_Tr\n",
        "            else:\n",
        "              epoch_nloss_All = epoch_loss_All / var_Tt\n",
        "              epoch_nloss_I   = epoch_loss_I / var_Tt\n",
        "              epoch_nloss_R   = epoch_loss_R / var_Tt\n",
        "              epoch_nloss_AE   = loss_AE / var_Tt\n",
        "\n",
        "            #print('{} Loss: {:.4f} '.format(\n",
        "             #   phase, epoch_loss))\n",
        "            print('{} Loss: {:.4f} NLossAll: {:.4f} NLossR: {:.4f} NLossI: {:.4f} NLossAE: {:.4f}'.format(\n",
        "                phase, epoch_loss,epoch_nloss_All,epoch_nloss_R,epoch_nloss_I,epoch_nloss_AE))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVpMDT5dZnbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create training/test data pytorch tensors and associated  \n",
        "# list of tensors (xx[n][x] to access the nth sample for the xth field)\n",
        "\n",
        "# no mask\n",
        "#training_dataset     = torch.utils.data.TensorDataset(torch.Tensor(x_train),torch.add(1.0,torch.mul(0.0,torch.Tensor(mask_train))),torch.Tensor(x_train)) # create your datset\n",
        "#test_dataset         = torch.utils.data.TensorDataset(torch.Tensor(x_test),torch.add(1.0,torch.mul(0.0,torch.Tensor(mask_test))),torch.Tensor(x_test)) # create your datset\n",
        "\n",
        "training_dataset     = torch.utils.data.TensorDataset(torch.Tensor(x_train_missing),torch.Tensor(mask_train),torch.Tensor(x_train)) # create your datset\n",
        "test_dataset         = torch.utils.data.TensorDataset(torch.Tensor(x_test_missing),torch.Tensor(mask_test),torch.Tensor(x_test)) # create your datset\n",
        "\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True),\n",
        "    'val': torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True),\n",
        "}\n",
        "\n",
        "dataset_sizes = {'train': len(training_dataset), 'val': len(test_dataset)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6pS0oGzZodA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "b5375dcd-9e98-42de-8233-a601b3f1f8d5"
      },
      "source": [
        "#  use gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# mean-squared error loss\n",
        "#criterion = torch.nn.MSELoss()\n",
        "var_Tr    = np.var( x_train )\n",
        "var_Tt    = np.var( x_test )\n",
        "\n",
        "if 1*0:\n",
        "  model_AE2    = Model_AE()\n",
        "\n",
        "if 1*1:\n",
        "    alpha           = np.array([1.0,0.1])\n",
        "    GradType        = 0 # Gradient computation (0: subgradient, 1: true gradient/autograd)\n",
        "    OptimType       = 0 # 0: fixed-step gradient descent, 1: ConvNet_step gradient descent, 2: LSTM-based descent\n",
        "    NiterProjection = 2 # Number of fixed-point iterations\n",
        "    NiterGrad       = 10 # Number of gradient descent step\n",
        "    \n",
        "    # NiterProjection,NiterGrad: global variables\n",
        "    # bug for NiterProjection = 0\n",
        "    shapeData       = x_train.shape[1:]\n",
        "    model_AE_GradFP = dinAE.Model_AE_GradFP(model_AE2,shapeData,NiterProjection,NiterGrad,GradType,OptimType)\n",
        "\n",
        "    model_AE_GradFP = model_AE_GradFP.to(device)\n",
        "\n",
        "    # create an optimizer object\n",
        "    # Adam optimizer with learning rate 1e-3\n",
        "    optimizer        = optim.Adam(model_AE_GradFP.parameters(), lr=1e-3)\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "\n",
        "model_AE_GradFP = train_model(model_AE_GradFP, optimizer, exp_lr_scheduler,\n",
        "                       alpha,num_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 0.4034 NLossAll: 0.6161 NLossR: 1.2239 NLossI: 0.3934 NLossAE: 0.0322\n",
            "val Loss: 0.1763 NLossAll: 0.3583 NLossR: 0.8782 NLossI: 0.1688 NLossAE: 0.0470\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 0.1477 NLossAll: 0.3447 NLossR: 0.8964 NLossI: 0.1438 NLossAE: 0.0475\n",
            "val Loss: 0.1274 NLossAll: 0.3266 NLossR: 0.8871 NLossI: 0.1223 NLossAE: 0.0244\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ByMbcI1LdCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dddb9f76-af2c-4318-996c-3035b877eec8"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVDi-qLfXhRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "a6451a62-a195-47c9-e7e1-7253de04badd"
      },
      "source": [
        "### Visualisation of results\n",
        "### Apply model to test data\n",
        "\n",
        "def compute_loss(outputs,inputs_GT,outputs_AE,masks,shapeData):\n",
        "\n",
        "  # masked loss\n",
        "  diff = (outputs - inputs_GT)**2 * masks\n",
        "  masked_loss = torch.sum(diff.view(-1,shapeData[0]*shapeData[1]*shapeData[2]) , 1 )\n",
        "  masked_loss = masked_loss / torch.sum(masks.view(-1,shapeData[0]*shapeData[1]*shapeData[2]) , 1 )\n",
        "\n",
        "  # loss GT\n",
        "  diff = (outputs - inputs_GT)**2\n",
        "  loss_GT = torch.mean(diff.view(-1,shapeData[0]*shapeData[1]*shapeData[2]) , 1 )\n",
        "\n",
        "  # loss AE\n",
        "  diff = (outputs - outputs_AE)**2\n",
        "  loss_AE = torch.mean(diff.view(-1,shapeData[0]*shapeData[1]*shapeData[2]) , 1 )\n",
        "\n",
        "  return masked_loss,loss_GT,loss_AE\n",
        "\n",
        "# apply model\n",
        "outputs = []\n",
        "\n",
        "for inputs_missing,masks,inputs_GT in dataloaders['val']:\n",
        "  inputs_missing = inputs_missing.to(device)\n",
        "  masks          = masks.to(device)\n",
        "  inputs_GT      = inputs_GT.to(device)\n",
        "  with torch.set_grad_enabled(True): \n",
        "  #with torch.set_grad_enabled(phase == 'train'):\n",
        "      outputs_ = model_AE_GradFP(inputs_missing,masks)\n",
        "\n",
        "  # MSE\n",
        "  masked_loss_,loss_GT_,loss_AE_ = compute_loss(outputs_,inputs_GT,model_AE_GradFP.model_AE(outputs_),masks,shapeData)\n",
        "\n",
        "  if len(outputs) == 0:\n",
        "    outputs  = torch.mul(1.0,outputs_)\n",
        "    masked_loss = masked_loss_\n",
        "    loss_GT     = loss_GT_\n",
        "    loss_AE     = loss_AE_\n",
        "  else:\n",
        "    outputs     = torch.cat((outputs,outputs_),0)\n",
        "    masked_loss = torch.cat((masked_loss,masked_loss_),0)\n",
        "    loss_GT     = torch.cat((loss_GT,loss_GT_),0)\n",
        "    loss_AE     = torch.cat((loss_AE,loss_AE_),0)\n",
        "                    \n",
        "mean_masked_loss = torch.mean( masked_loss ).cpu().detach().numpy()\n",
        "mean_loss_GT     = torch.mean( loss_GT ).cpu().detach().numpy()\n",
        "mean_loss_AE     = torch.mean( loss_AE ).cpu().detach().numpy()\n",
        "\n",
        "v = np.var(x_test[:,:,:])\n",
        "\n",
        "# Visualisation\n",
        "# visualize missing data pattern for test data\n",
        "plt.figure()\n",
        "for ii in range(5):\n",
        "    plt.subplot(3, 5, ii + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inputs_GT[ii,:,:].cpu().detach().numpy().squeeze(), cmap=plt.cm.gray_r)\n",
        "    plt.title('GT')\n",
        "    plt.subplot(3, 5, ii + 1+5)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inputs_missing[ii,:,:].cpu().detach().numpy().squeeze(), cmap=plt.cm.gray_r)\n",
        "    plt.title('Obs')\n",
        "    plt.subplot(3, 5, ii + 1+10)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(outputs[ii,:,:].cpu().detach().numpy().squeeze(), cmap=plt.cm.gray_r)\n",
        "    plt.title('Obs')\n",
        "plt.show()\n",
        "\n",
        "print('# Random test dataset: NLossMask: {:.4f} NLossGT: {:.4f} NLossAE: {:.4f}'.format(\n",
        "      mean_masked_loss/v, mean_loss_GT/v,mean_loss_AE/v))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0d497c576a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs_missing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs_GT\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0minputs_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_missing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mmasks\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xMgXEsMfVsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6a5fc5c-f7f8-4799-c3cf-895b154bd9fd"
      },
      "source": [
        "print(outputs.size())"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([896, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}